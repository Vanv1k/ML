{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  -  Выберите набор данных (датасет) для решения задачи классификации или регрессии.\n",
    "  -  В случае необходимости проведите удаление или заполнение пропусков и кодирование категориальных признаков.\n",
    "  -  С использованием метода train_test_split разделите выборку на обучающую и тестовую.\n",
    "  -  Обучите модель ближайших соседей для произвольно заданного гиперпараметра K. Оцените качество модели с помощью подходящих для задачи метрик.\n",
    "  -  Произведите подбор гиперпараметра K с использованием GridSearchCV и RandomizedSearchCV и кросс-валидации, оцените качество оптимальной модели. Используйте не менее двух стратегий кросс-валидации.\n",
    "  - Сравните метрики качества исходной и оптимальной моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбранный датасет (алмазы):\n",
    "Содержание:\n",
    "- Цена в долларах США ($326--$18,823)\n",
    "- Карат  (0.2--5.01)\n",
    "- Качество обрезки (Низкое, Хорошее, Очень хорошее, Премиум, Идеальное)\n",
    "- Цвет бриллианта, от J (худший) до D (лучший)\n",
    "- Измерение прозрачности бриллианта (I1 (худшее), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (лучшее))\n",
    "- X длина в мм (0--10.74)\n",
    "- Y ширина в мм (0--58.9)\n",
    "- Z глубина в мм (0--31.8)\n",
    "- Общий процент глубины = z / среднее(x, y) = 2 * z / (x + y) (43--79)\n",
    "- Ширина вершины бриллианта относительно самой широкой точки (43--95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53940, 11), (53940,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           int64\n",
       "carat      float64\n",
       "cut         object\n",
       "color       object\n",
       "clarity     object\n",
       "depth      float64\n",
       "table      float64\n",
       "price        int64\n",
       "x          float64\n",
       "y          float64\n",
       "z          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "carat      0\n",
       "cut        0\n",
       "color      0\n",
       "clarity    0\n",
       "depth      0\n",
       "table      0\n",
       "price      0\n",
       "x          0\n",
       "y          0\n",
       "z          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущенных значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  carat  depth  table  price     x     y     z  cut_encoded  \\\n",
      "0          1   0.23   61.5   55.0    326  3.95  3.98  2.43            4   \n",
      "1          2   0.21   59.8   61.0    326  3.89  3.84  2.31            3   \n",
      "2          3   0.23   56.9   65.0    327  4.05  4.07  2.31            1   \n",
      "3          4   0.29   62.4   58.0    334  4.20  4.23  2.63            3   \n",
      "4          5   0.31   63.3   58.0    335  4.34  4.35  2.75            1   \n",
      "...      ...    ...    ...    ...    ...   ...   ...   ...          ...   \n",
      "53935  53936   0.72   60.8   57.0   2757  5.75  5.76  3.50            4   \n",
      "53936  53937   0.72   63.1   55.0   2757  5.69  5.75  3.61            1   \n",
      "53937  53938   0.70   62.8   60.0   2757  5.66  5.68  3.56            2   \n",
      "53938  53939   0.86   61.0   58.0   2757  6.15  6.12  3.74            3   \n",
      "53939  53940   0.75   62.2   55.0   2757  5.83  5.87  3.64            4   \n",
      "\n",
      "       color_encoded  clarity_encoded  \n",
      "0                  5                1  \n",
      "1                  5                2  \n",
      "2                  5                4  \n",
      "3                  1                3  \n",
      "4                  0                1  \n",
      "...              ...              ...  \n",
      "53935              6                2  \n",
      "53936              6                2  \n",
      "53937              6                2  \n",
      "53938              2                1  \n",
      "53939              6                1  \n",
      "\n",
      "[53940 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "cut_order = {'Fair': 0, 'Good': 1, 'Very Good': 2, 'Premium': 3, 'Ideal': 4}\n",
    "color_order = {'J': 0, 'I': 1, 'H': 2, 'G': 3, 'F': 4, 'E': 5, 'D': 6}\n",
    "clarity_order = {'I1': 0, 'SI2': 1, 'SI1': 2, 'VS2': 3, 'VS1': 4, 'VVS2': 5, 'VVS1': 6, 'IF': 7}\n",
    "df['cut_encoded'] = df['cut'].map(cut_order)\n",
    "df['color_encoded'] = df['color'].map(color_order)\n",
    "df['clarity_encoded'] = df['clarity'].map(clarity_order)\n",
    "df_encoded = df.drop(columns=['cut', 'color', 'clarity'])\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим вектор переменных целевого признака, и матрицу признаков(без целевого)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(\"price\", axis=1)\n",
    "y = df_encoded[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  carat  depth  table     x     y     z  cut_encoded  color_encoded  \\\n",
      "0   1   0.23   61.5   55.0  3.95  3.98  2.43            4              5   \n",
      "1   2   0.21   59.8   61.0  3.89  3.84  2.31            3              5   \n",
      "2   3   0.23   56.9   65.0  4.05  4.07  2.31            1              5   \n",
      "3   4   0.29   62.4   58.0  4.20  4.23  2.63            3              1   \n",
      "4   5   0.31   63.3   58.0  4.34  4.35  2.75            1              0   \n",
      "\n",
      "   clarity_encoded  \n",
      "0                1  \n",
      "1                2  \n",
      "2                4  \n",
      "3                3  \n",
      "4                1   \n",
      "\n",
      "0    326\n",
      "1    326\n",
      "2    327\n",
      "3    334\n",
      "4    335\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.head(), \"\\n\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40455, 10), (40455,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13485, 10), (13485,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели ближайших соседей для произвольно заданного гиперпараметра K. Оценка качества модели с помощью подходящих для задачи метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13485,\n",
       " array([ 563.35714286, 5914.71428571, 2562.14285714, ..., 3286.07142857,\n",
       "        3733.85714286, 1362.92857143]))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_i = KNeighborsRegressor(n_neighbors=14)\n",
    "clf_i.fit(X_train, y_train)\n",
    "y_pred = clf_i.predict(X_test)\n",
    "len(y_pred), y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 109.04176598336775\n",
      "Mean Squared Error: 303046.2055038478\n",
      "R-squared Score: 0.980401117236128\n"
     ]
    }
   ],
   "source": [
    "# Вычисление средней абсолютной ошибки\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Вычисление средней квадратичной ошибки\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Вычисление коэффициента детерминации\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2714      564\n",
       "14653    5914\n",
       "52760    2562\n",
       "48658     537\n",
       "14812    5964\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметра K с использованием GridSearchCV и RandomizedSearchCV и кросс-валидации, оценка качество оптимальной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Задаем пространство поиска гиперпараметра K для GridSearchCV\n",
    "param_grid = {'n_neighbors': np.arange(1, 21)}\n",
    "\n",
    "# Задаем пространство поиска гиперпараметра K для RandomizedSearchCV\n",
    "param_dist = {'n_neighbors': np.random.randint(1, 21, 10)}\n",
    "\n",
    "# Создаем объект для среднеквадратичной ошибки (MSE)\n",
    "mse_scorer = make_scorer(mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем GridSearchCV\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring=mse_scorer)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получаем оптимальное значение гиперпараметра K\n",
    "optimal_k_grid = grid_search.best_params_['n_neighbors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_neighbors': 20}\n",
      "Лучшая оценка точности: 601444.8013628104\n"
     ]
    }
   ],
   "source": [
    "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
    "print(\"Лучшая оценка среднеквадратичной ошибки:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты кросс-валидации:\n",
      "{'mean_fit_time': array([0.09279599, 0.09398236, 0.09409814, 0.1053082 , 0.09882746,\n",
      "       0.10410357, 0.0965457 , 0.09244637, 0.09257245, 0.09342775,\n",
      "       0.09199548, 0.09364758, 0.09754262, 0.09590735, 0.09588385,\n",
      "       0.09100242, 0.08847895, 0.08789721, 0.09055843, 0.09112573]), 'std_fit_time': array([0.00293514, 0.00177147, 0.0032515 , 0.00669447, 0.00306637,\n",
      "       0.01049999, 0.00356681, 0.00172587, 0.00189465, 0.00237198,\n",
      "       0.00064219, 0.0007525 , 0.00437408, 0.00570949, 0.00577967,\n",
      "       0.00254459, 0.00118219, 0.00076338, 0.00291123, 0.00200385]), 'mean_score_time': array([0.03602352, 0.03520193, 0.03729749, 0.04579282, 0.04165211,\n",
      "       0.04295373, 0.04052162, 0.03584752, 0.03685274, 0.03888483,\n",
      "       0.03793411, 0.04074759, 0.04516377, 0.04355192, 0.0403306 ,\n",
      "       0.03678441, 0.03681321, 0.03817787, 0.03976479, 0.04421868]), 'std_score_time': array([0.00121986, 0.00401333, 0.00357205, 0.00262782, 0.00321853,\n",
      "       0.0020068 , 0.00315641, 0.00072866, 0.00067222, 0.00337601,\n",
      "       0.00109572, 0.00269818, 0.00811525, 0.00409027, 0.00312375,\n",
      "       0.00177105, 0.0014033 , 0.00039675, 0.00191203, 0.00253375]), 'param_n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
      "                   17, 18, 19, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 2}, {'n_neighbors': 3}, {'n_neighbors': 4}, {'n_neighbors': 5}, {'n_neighbors': 6}, {'n_neighbors': 7}, {'n_neighbors': 8}, {'n_neighbors': 9}, {'n_neighbors': 10}, {'n_neighbors': 11}, {'n_neighbors': 12}, {'n_neighbors': 13}, {'n_neighbors': 14}, {'n_neighbors': 15}, {'n_neighbors': 16}, {'n_neighbors': 17}, {'n_neighbors': 18}, {'n_neighbors': 19}, {'n_neighbors': 20}], 'split0_test_score': array([ 67742.82227166,  75971.29464837,  83545.30706272, 115410.0130778 ,\n",
      "       139841.39808182, 169969.41054532, 212299.28512406, 245581.80277083,\n",
      "       269420.89213743, 293642.17184402, 327068.03630807, 357731.10262775,\n",
      "       395730.37651741, 422385.32773755, 452658.85777833, 476417.56954149,\n",
      "       494493.31617471, 536761.33738753, 563029.69835709, 596446.73334013]), 'split1_test_score': array([ 24672.36423186,  48042.83645408,  73226.5707027 ,  89781.11247837,\n",
      "       132672.65476208, 169470.10111715, 196857.62826169, 221972.71695209,\n",
      "       259349.29619101, 276257.07853294, 310318.15537313, 331252.48692048,\n",
      "       360814.15085503, 388704.07396856, 422189.54401846, 459402.77631879,\n",
      "       489859.45232924, 528362.75109022, 562978.6214278 , 606150.64904276]), 'split2_test_score': array([ 33559.13545915,  35507.83979113,  53432.74358341,  71595.66196237,\n",
      "       105611.99049808, 138898.22562793, 171177.64120123, 199287.76246563,\n",
      "       234200.35526137, 262135.25197009, 294224.0766355 , 328211.93920028,\n",
      "       365192.41088974, 399307.20577348, 428852.78864637, 454549.72795245,\n",
      "       486278.02701152, 514766.27041782, 554532.33596339, 589542.38755315]), 'split3_test_score': array([ 31329.55073538,  64066.41957113,  73495.77466046,  77287.96689223,\n",
      "        94256.09100482, 124755.61144756, 135315.21300311, 173169.71697913,\n",
      "       206534.99898683, 245415.04150538, 274647.79275514, 304883.27356528,\n",
      "       343351.87726812, 374304.36138415, 411131.10916766, 442969.67485767,\n",
      "       476951.55646177, 508801.46936125, 553013.42623057, 581931.70391701]), 'split4_test_score': array([ 74451.89692251,  73594.18396984,  84470.35724193, 108633.59820325,\n",
      "       143820.96514646, 172438.5876042 , 203338.7704832 , 241941.19498903,\n",
      "       275421.60523886, 311314.37426029, 347264.4430226 , 396979.72315261,\n",
      "       433335.93328185, 458505.24455051, 489802.00504099, 514420.30462667,\n",
      "       542215.25425021, 573078.6227446 , 606838.6709839 , 633152.53296101]), 'mean_test_score': array([ 46351.15392411,  59436.51488691,  73634.15065024,  92541.6705228 ,\n",
      "       123240.61989865, 155106.38726843, 183797.70761466, 216390.63883134,\n",
      "       248985.4295631 , 277752.78362254, 310704.50081889, 343811.70509328,\n",
      "       379684.94976243, 408641.24268285, 440926.86093036, 469552.01065941,\n",
      "       497959.52124549, 532354.09020028, 568078.55059255, 601444.80136281]), 'std_test_score': array([20525.63983432, 15476.89861101, 11170.82370766, 17093.52308604,\n",
      "       19692.49206277, 19552.51902763, 27837.28774828, 27190.70074121,\n",
      "       25473.62056986, 23111.58591726, 25204.10485658, 31423.2309298 ,\n",
      "       31692.6383995 , 29458.2922619 , 27968.11238377, 24879.6934189 ,\n",
      "       22864.76542507, 22618.13219389, 19820.72159107, 17747.8694827 ]), 'rank_test_score': array([20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,\n",
      "        3,  2,  1])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Результаты кросс-валидации:\")\n",
    "print(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Лучшая модель:\n",
      "KNeighborsRegressor(n_neighbors=20)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nЛучшая модель:\")\n",
    "print(grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Средние значения метрики по кросс-валидации:\n",
      "[ 46351.15392411  59436.51488691  73634.15065024  92541.6705228\n",
      " 123240.61989865 155106.38726843 183797.70761466 216390.63883134\n",
      " 248985.4295631  277752.78362254 310704.50081889 343811.70509328\n",
      " 379684.94976243 408641.24268285 440926.86093036 469552.01065941\n",
      " 497959.52124549 532354.09020028 568078.55059255 601444.80136281]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСредние значения метрики по кросс-валидации:\")\n",
    "print(grid_search.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Стандартное отклонение метрики по кросс-валидации:\n",
      "[20525.63983432 15476.89861101 11170.82370766 17093.52308604\n",
      " 19692.49206277 19552.51902763 27837.28774828 27190.70074121\n",
      " 25473.62056986 23111.58591726 25204.10485658 31423.2309298\n",
      " 31692.6383995  29458.2922619  27968.11238377 24879.6934189\n",
      " 22864.76542507 22618.13219389 19820.72159107 17747.8694827 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСтандартное отклонение метрики по кросс-валидации:\")\n",
    "print(grid_search.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение качества на тестовой выборке в зависимости от К-соседей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17f81b1ea50>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, 21), grid_search.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Используем RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(knn, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Получаем оптимальное значение гиперпараметра K\n",
    "optimal_k_random = random_search.best_params_['n_neighbors']\n",
    "\n",
    "# Оцениваем качество оптимальной модели\n",
    "accuracy_random = random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_neighbors': 3}\n",
      "Лучшая оценка точности: 0.689655172413793\n"
     ]
    }
   ],
   "source": [
    "print(\"Лучшие параметры:\", random_search.best_params_)\n",
    "print(\"Лучшая оценка точности:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты кросс-валидации:\n",
      "{'mean_fit_time': array([0.09886489, 0.10250082, 0.10456305, 0.09861054, 0.10314331,\n",
      "       0.1011992 , 0.09885659, 0.09939313, 0.10065713, 0.10666857]), 'std_fit_time': array([0.00208972, 0.00533237, 0.00980068, 0.00247603, 0.00161985,\n",
      "       0.002913  , 0.00376441, 0.00622105, 0.00789994, 0.00748472]), 'mean_score_time': array([0.32124805, 0.32391577, 0.33318262, 0.32568369, 0.33784795,\n",
      "       0.31701837, 0.31102324, 0.31612396, 0.3389092 , 0.3414659 ]), 'std_score_time': array([0.01039448, 0.00587623, 0.01751304, 0.01581539, 0.03777757,\n",
      "       0.01155378, 0.00405018, 0.00512189, 0.01737869, 0.01500702]), 'param_n_neighbors': masked_array(data=[13, 11, 17, 13, 5, 3, 9, 9, 15, 18],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 13}, {'n_neighbors': 11}, {'n_neighbors': 17}, {'n_neighbors': 13}, {'n_neighbors': 5}, {'n_neighbors': 3}, {'n_neighbors': 9}, {'n_neighbors': 9}, {'n_neighbors': 15}, {'n_neighbors': 18}], 'split0_test_score': array([0.57051044, 0.60375726, 0.51538747, 0.57051044, 0.69014955,\n",
      "       0.6870597 , 0.63329626, 0.63329626, 0.54109504, 0.50463478]), 'split1_test_score': array([0.57026326, 0.59918428, 0.51439871, 0.57026326, 0.69002595,\n",
      "       0.69039674, 0.63082437, 0.63082437, 0.54035348, 0.50327524]), 'split2_test_score': array([0.57026326, 0.60165616, 0.51328637, 0.57026326, 0.68557657,\n",
      "       0.69163268, 0.63354344, 0.63354344, 0.53911754, 0.49969101]), 'split3_test_score': array([0.57236436, 0.59992584, 0.51217402, 0.57236436, 0.68681251,\n",
      "       0.69299221, 0.63428501, 0.63428501, 0.54134223, 0.49932023]), 'split4_test_score': array([0.57162279, 0.6051168 , 0.51427512, 0.57162279, 0.67630701,\n",
      "       0.68619454, 0.63131875, 0.63131875, 0.54035348, 0.50166852]), 'mean_test_score': array([0.57100482, 0.60192807, 0.51390434, 0.57100482, 0.68577432,\n",
      "       0.68965517, 0.63265357, 0.63265357, 0.54045235, 0.50171796]), 'std_test_score': array([0.00084551, 0.00224166, 0.00109155, 0.00084551, 0.00505897,\n",
      "       0.0026195 , 0.00134121, 0.00134121, 0.0007754 , 0.00203927]), 'rank_test_score': array([ 6,  5,  9,  6,  2,  1,  3,  3,  8, 10])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Результаты кросс-валидации:\")\n",
    "print(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Лучшая модель:\n",
      "KNeighborsClassifier(n_neighbors=3)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nЛучшая модель:\")\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Средние значения метрики по кросс-валидации:\n",
      "[0.57100482 0.60192807 0.51390434 0.57100482 0.68577432 0.68965517\n",
      " 0.63265357 0.63265357 0.54045235 0.50171796]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСредние значения метрики по кросс-валидации:\")\n",
    "print(random_search.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Стандартное отклонение метрики по кросс-валидации:\n",
      "[0.00084551 0.00224166 0.00109155 0.00084551 0.00505897 0.0026195\n",
      " 0.00134121 0.00134121 0.0007754  0.00203927]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСтандартное отклонение метрики по кросс-валидации:\")\n",
    "print(random_search.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение оптимальной модели (k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13485, array([ 564, 5914, 2562, ..., 3286, 3734, 1363], dtype=int64))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_o = KNeighborsClassifier(n_neighbors=1)\n",
    "clf_o.fit(X_train, y_train)\n",
    "target_o = clf_o.predict(X_test)\n",
    "len(target_o), target_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение метрик качества исходной и оптимальной моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5451983685576567"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# исходная модель\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714275120504264"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, target_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    classes = np.unique(y_true)\n",
    "    res = dict()\n",
    "    for c in classes:\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{327: 0.0,\n",
       " 339: 0.0,\n",
       " 340: 0.0,\n",
       " 342: 0.0,\n",
       " 353: 0.0,\n",
       " 354: 0.0,\n",
       " 357: 0.0,\n",
       " 363: 0.0,\n",
       " 364: 0.0,\n",
       " 367: 0.5,\n",
       " 368: 0.0,\n",
       " 373: 0.0,\n",
       " 374: 0.0,\n",
       " 376: 0.0,\n",
       " 378: 1.0,\n",
       " 379: 0.0,\n",
       " 380: 0.0,\n",
       " 382: 1.0,\n",
       " 383: 0.0,\n",
       " 384: 0.0,\n",
       " 386: 0.0,\n",
       " 388: 1.0,\n",
       " 389: 0.0,\n",
       " 391: 1.0,\n",
       " 393: 0.6,\n",
       " 394: 1.0,\n",
       " 397: 0.0,\n",
       " 399: 1.0,\n",
       " 400: 0.0,\n",
       " 401: 0.5,\n",
       " 402: 1.0,\n",
       " 403: 1.0,\n",
       " 404: 1.0,\n",
       " 405: 0.0,\n",
       " 407: 1.0,\n",
       " 408: 1.0,\n",
       " 409: 0.0,\n",
       " 411: 0.0,\n",
       " 412: 0.0,\n",
       " 413: 0.4,\n",
       " 415: 0.0,\n",
       " 416: 0.0,\n",
       " 417: 1.0,\n",
       " 418: 0.5,\n",
       " 419: 1.0,\n",
       " 420: 0.0,\n",
       " 421: 0.9473684210526315,\n",
       " 422: 1.0,\n",
       " 424: 0.0,\n",
       " 425: 0.0,\n",
       " 426: 0.0,\n",
       " 427: 1.0,\n",
       " 429: 1.0,\n",
       " 430: 0.5,\n",
       " 431: 1.0,\n",
       " 432: 0.8181818181818182,\n",
       " 434: 1.0,\n",
       " 435: 1.0,\n",
       " 436: 0.75,\n",
       " 438: 0.5,\n",
       " 439: 1.0,\n",
       " 440: 0.0,\n",
       " 441: 0.0,\n",
       " 442: 1.0,\n",
       " 445: 1.0,\n",
       " 446: 1.0,\n",
       " 447: 1.0,\n",
       " 449: 1.0,\n",
       " 450: 0.2857142857142857,\n",
       " 451: 0.0,\n",
       " 452: 0.8,\n",
       " 453: 0.5,\n",
       " 454: 1.0,\n",
       " 456: 0.0,\n",
       " 457: 1.0,\n",
       " 458: 0.5,\n",
       " 459: 0.2857142857142857,\n",
       " 460: 0.0,\n",
       " 461: 0.7777777777777778,\n",
       " 462: 1.0,\n",
       " 463: 0.6,\n",
       " 464: 1.0,\n",
       " 465: 1.0,\n",
       " 466: 0.0,\n",
       " 467: 0.0,\n",
       " 468: 1.0,\n",
       " 469: 0.0,\n",
       " 470: 1.0,\n",
       " 471: 1.0,\n",
       " 472: 0.6666666666666666,\n",
       " 473: 1.0,\n",
       " 474: 0.0,\n",
       " 475: 1.0,\n",
       " 477: 0.9285714285714286,\n",
       " 478: 1.0,\n",
       " 480: 0.6666666666666666,\n",
       " 481: 0.0,\n",
       " 482: 1.0,\n",
       " 484: 1.0,\n",
       " 485: 0.75,\n",
       " 486: 1.0,\n",
       " 487: 0.8571428571428571,\n",
       " 489: 1.0,\n",
       " 490: 0.8,\n",
       " 491: 1.0,\n",
       " 492: 1.0,\n",
       " 493: 1.0,\n",
       " 495: 0.0,\n",
       " 496: 0.0,\n",
       " 499: 0.6,\n",
       " 500: 0.8,\n",
       " 502: 0.0,\n",
       " 503: 1.0,\n",
       " 504: 0.6666666666666666,\n",
       " 505: 0.9565217391304348,\n",
       " 506: 1.0,\n",
       " 507: 0.8,\n",
       " 508: 0.0,\n",
       " 511: 0.0,\n",
       " 512: 0.0,\n",
       " 513: 1.0,\n",
       " 514: 0.0,\n",
       " 515: 1.0,\n",
       " 516: 1.0,\n",
       " 517: 0.5,\n",
       " 518: 1.0,\n",
       " 520: 0.0,\n",
       " 521: 0.875,\n",
       " 522: 1.0,\n",
       " 523: 0.8333333333333334,\n",
       " 524: 1.0,\n",
       " 525: 1.0,\n",
       " 526: 0.96,\n",
       " 528: 0.0,\n",
       " 529: 0.6666666666666666,\n",
       " 530: 1.0,\n",
       " 532: 1.0,\n",
       " 533: 0.625,\n",
       " 536: 0.0,\n",
       " 537: 1.0,\n",
       " 538: 0.5,\n",
       " 539: 1.0,\n",
       " 540: 1.0,\n",
       " 541: 0.5,\n",
       " 543: 0.0,\n",
       " 544: 1.0,\n",
       " 545: 0.8333333333333334,\n",
       " 547: 0.5,\n",
       " 548: 0.8888888888888888,\n",
       " 549: 0.0,\n",
       " 550: 1.0,\n",
       " 551: 1.0,\n",
       " 552: 1.0,\n",
       " 553: 0.0,\n",
       " 554: 1.0,\n",
       " 555: 0.25,\n",
       " 556: 0.5,\n",
       " 557: 1.0,\n",
       " 558: 0.875,\n",
       " 559: 1.0,\n",
       " 560: 0.0,\n",
       " 561: 0.9,\n",
       " 562: 0.5,\n",
       " 563: 0.0,\n",
       " 564: 1.0,\n",
       " 565: 0.6,\n",
       " 566: 0.6666666666666666,\n",
       " 567: 1.0,\n",
       " 568: 1.0,\n",
       " 569: 0.0,\n",
       " 570: 1.0,\n",
       " 571: 0.9230769230769231,\n",
       " 572: 1.0,\n",
       " 573: 0.7272727272727273,\n",
       " 574: 0.75,\n",
       " 575: 1.0,\n",
       " 576: 1.0,\n",
       " 577: 1.0,\n",
       " 578: 0.0,\n",
       " 579: 0.875,\n",
       " 580: 1.0,\n",
       " 581: 1.0,\n",
       " 583: 0.9230769230769231,\n",
       " 584: 1.0,\n",
       " 586: 1.0,\n",
       " 587: 1.0,\n",
       " 588: 0.0,\n",
       " 589: 1.0,\n",
       " 590: 1.0,\n",
       " 591: 1.0,\n",
       " 593: 1.0,\n",
       " 594: 1.0,\n",
       " 595: 1.0,\n",
       " 596: 1.0,\n",
       " 597: 0.8333333333333334,\n",
       " 598: 0.25,\n",
       " 599: 1.0,\n",
       " 600: 1.0,\n",
       " 601: 0.0,\n",
       " 602: 1.0,\n",
       " 603: 0.75,\n",
       " 605: 1.0,\n",
       " 606: 0.6666666666666666,\n",
       " 607: 0.6,\n",
       " 608: 0.9545454545454546,\n",
       " 609: 0.5,\n",
       " 610: 1.0,\n",
       " 611: 1.0,\n",
       " 612: 0.9375,\n",
       " 613: 1.0,\n",
       " 614: 0.7142857142857143,\n",
       " 615: 0.3333333333333333,\n",
       " 616: 1.0,\n",
       " 617: 0.5,\n",
       " 618: 1.0,\n",
       " 619: 1.0,\n",
       " 620: 0.875,\n",
       " 621: 1.0,\n",
       " 622: 0.7777777777777778,\n",
       " 624: 1.0,\n",
       " 625: 0.9393939393939394,\n",
       " 626: 1.0,\n",
       " 627: 1.0,\n",
       " 628: 0.8,\n",
       " 629: 0.6666666666666666,\n",
       " 630: 0.8571428571428571,\n",
       " 631: 1.0,\n",
       " 632: 0.0,\n",
       " 633: 1.0,\n",
       " 635: 0.75,\n",
       " 636: 1.0,\n",
       " 637: 0.3333333333333333,\n",
       " 638: 1.0,\n",
       " 639: 1.0,\n",
       " 640: 0.6,\n",
       " 641: 1.0,\n",
       " 642: 1.0,\n",
       " 644: 0.9090909090909091,\n",
       " 645: 0.9354838709677419,\n",
       " 646: 1.0,\n",
       " 647: 1.0,\n",
       " 648: 1.0,\n",
       " 649: 1.0,\n",
       " 650: 1.0,\n",
       " 651: 0.8333333333333334,\n",
       " 652: 0.0,\n",
       " 653: 1.0,\n",
       " 654: 0.0,\n",
       " 655: 1.0,\n",
       " 656: 0.0,\n",
       " 657: 1.0,\n",
       " 658: 1.0,\n",
       " 659: 0.5,\n",
       " 660: 1.0,\n",
       " 661: 1.0,\n",
       " 662: 0.8,\n",
       " 663: 0.9166666666666666,\n",
       " 664: 1.0,\n",
       " 665: 1.0,\n",
       " 666: 1.0,\n",
       " 667: 1.0,\n",
       " 668: 0.9230769230769231,\n",
       " 669: 1.0,\n",
       " 670: 0.8333333333333334,\n",
       " 671: 1.0,\n",
       " 672: 1.0,\n",
       " 673: 1.0,\n",
       " 675: 0.9615384615384616,\n",
       " 676: 1.0,\n",
       " 677: 0.0,\n",
       " 678: 1.0,\n",
       " 679: 1.0,\n",
       " 680: 0.9130434782608695,\n",
       " 681: 1.0,\n",
       " 682: 1.0,\n",
       " 683: 1.0,\n",
       " 684: 0.875,\n",
       " 685: 0.5,\n",
       " 686: 0.8888888888888888,\n",
       " 687: 1.0,\n",
       " 688: 0.0,\n",
       " 689: 1.0,\n",
       " 691: 0.0,\n",
       " 692: 1.0,\n",
       " 693: 0.6,\n",
       " 694: 1.0,\n",
       " 695: 1.0,\n",
       " 696: 1.0,\n",
       " 697: 0.0,\n",
       " 698: 0.9714285714285714,\n",
       " 699: 0.0,\n",
       " 700: 1.0,\n",
       " 701: 0.0,\n",
       " 702: 1.0,\n",
       " 703: 1.0,\n",
       " 704: 0.8333333333333334,\n",
       " 705: 1.0,\n",
       " 706: 0.9285714285714286,\n",
       " 707: 1.0,\n",
       " 708: 1.0,\n",
       " 709: 1.0,\n",
       " 710: 1.0,\n",
       " 711: 1.0,\n",
       " 713: 1.0,\n",
       " 714: 1.0,\n",
       " 715: 0.5,\n",
       " 716: 1.0,\n",
       " 717: 0.0,\n",
       " 718: 0.75,\n",
       " 719: 1.0,\n",
       " 720: 1.0,\n",
       " 721: 0.8,\n",
       " 722: 1.0,\n",
       " 723: 1.0,\n",
       " 724: 0.5,\n",
       " 725: 0.7142857142857143,\n",
       " 726: 1.0,\n",
       " 727: 0.6666666666666666,\n",
       " 728: 1.0,\n",
       " 729: 1.0,\n",
       " 730: 1.0,\n",
       " 731: 1.0,\n",
       " 732: 1.0,\n",
       " 733: 1.0,\n",
       " 734: 0.9375,\n",
       " 735: 1.0,\n",
       " 736: 1.0,\n",
       " 737: 0.9230769230769231,\n",
       " 738: 1.0,\n",
       " 739: 1.0,\n",
       " 740: 1.0,\n",
       " 741: 1.0,\n",
       " 742: 1.0,\n",
       " 743: 0.9333333333333333,\n",
       " 744: 1.0,\n",
       " 745: 0.8,\n",
       " 746: 1.0,\n",
       " 747: 1.0,\n",
       " 748: 0.6666666666666666,\n",
       " 749: 0.9,\n",
       " 750: 0.0,\n",
       " 751: 1.0,\n",
       " 752: 1.0,\n",
       " 753: 0.6,\n",
       " 754: 1.0,\n",
       " 755: 0.9,\n",
       " 756: 0.8666666666666667,\n",
       " 757: 1.0,\n",
       " 758: 1.0,\n",
       " 760: 0.8571428571428571,\n",
       " 761: 1.0,\n",
       " 763: 1.0,\n",
       " 764: 0.9285714285714286,\n",
       " 765: 1.0,\n",
       " 766: 1.0,\n",
       " 767: 0.75,\n",
       " 768: 0.75,\n",
       " 769: 0.8,\n",
       " 770: 1.0,\n",
       " 771: 1.0,\n",
       " 772: 1.0,\n",
       " 773: 0.9230769230769231,\n",
       " 774: 1.0,\n",
       " 775: 1.0,\n",
       " 776: 1.0,\n",
       " 777: 1.0,\n",
       " 778: 1.0,\n",
       " 779: 1.0,\n",
       " 780: 0.8888888888888888,\n",
       " 781: 1.0,\n",
       " 782: 0.0,\n",
       " 783: 0.0,\n",
       " 784: 1.0,\n",
       " 786: 1.0,\n",
       " 787: 0.8666666666666667,\n",
       " 788: 1.0,\n",
       " 789: 1.0,\n",
       " 790: 0.7142857142857143,\n",
       " 791: 1.0,\n",
       " 792: 1.0,\n",
       " 793: 0.0,\n",
       " 794: 1.0,\n",
       " 795: 1.0,\n",
       " 796: 1.0,\n",
       " 797: 0.0,\n",
       " 798: 1.0,\n",
       " 799: 0.8571428571428571,\n",
       " 800: 0.8,\n",
       " 801: 1.0,\n",
       " 802: 1.0,\n",
       " 803: 0.75,\n",
       " 804: 1.0,\n",
       " 805: 1.0,\n",
       " 806: 0.0,\n",
       " 807: 1.0,\n",
       " 808: 0.0,\n",
       " 810: 1.0,\n",
       " 811: 0.75,\n",
       " 812: 1.0,\n",
       " 813: 1.0,\n",
       " 814: 1.0,\n",
       " 815: 1.0,\n",
       " 816: 0.85,\n",
       " 817: 1.0,\n",
       " 818: 1.0,\n",
       " 819: 0.75,\n",
       " 820: 0.25,\n",
       " 821: 1.0,\n",
       " 823: 0.5,\n",
       " 824: 0.0,\n",
       " 825: 1.0,\n",
       " 826: 0.6666666666666666,\n",
       " 827: 1.0,\n",
       " 828: 1.0,\n",
       " 829: 1.0,\n",
       " 830: 0.8,\n",
       " 831: 0.0,\n",
       " 832: 1.0,\n",
       " 833: 1.0,\n",
       " 834: 1.0,\n",
       " 835: 1.0,\n",
       " 837: 1.0,\n",
       " 838: 1.0,\n",
       " 839: 0.5,\n",
       " 840: 1.0,\n",
       " 841: 1.0,\n",
       " 842: 1.0,\n",
       " 843: 0.0,\n",
       " 844: 1.0,\n",
       " 845: 0.0,\n",
       " 846: 1.0,\n",
       " 847: 1.0,\n",
       " 849: 0.3333333333333333,\n",
       " 850: 0.8333333333333334,\n",
       " 851: 1.0,\n",
       " 852: 1.0,\n",
       " 853: 0.8,\n",
       " 854: 0.9583333333333334,\n",
       " 855: 0.8571428571428571,\n",
       " 856: 0.0,\n",
       " 857: 1.0,\n",
       " 858: 1.0,\n",
       " 859: 0.5,\n",
       " 861: 0.0,\n",
       " 862: 1.0,\n",
       " 863: 1.0,\n",
       " 864: 1.0,\n",
       " 866: 0.6,\n",
       " 867: 1.0,\n",
       " 868: 1.0,\n",
       " 870: 0.5,\n",
       " 871: 0.8571428571428571,\n",
       " 872: 1.0,\n",
       " 873: 1.0,\n",
       " 874: 0.7272727272727273,\n",
       " 875: 1.0,\n",
       " 876: 1.0,\n",
       " 877: 0.75,\n",
       " 878: 1.0,\n",
       " 879: 0.8,\n",
       " 880: 1.0,\n",
       " 881: 0.0,\n",
       " 882: 1.0,\n",
       " 884: 0.5,\n",
       " 885: 0.0,\n",
       " 886: 1.0,\n",
       " 889: 1.0,\n",
       " 890: 1.0,\n",
       " 891: 1.0,\n",
       " 892: 1.0,\n",
       " 893: 1.0,\n",
       " 894: 1.0,\n",
       " 895: 0.7142857142857143,\n",
       " 896: 1.0,\n",
       " 897: 1.0,\n",
       " 898: 1.0,\n",
       " 899: 1.0,\n",
       " 900: 1.0,\n",
       " 901: 1.0,\n",
       " 902: 0.0,\n",
       " 904: 1.0,\n",
       " 905: 1.0,\n",
       " 906: 1.0,\n",
       " 907: 0.9375,\n",
       " 909: 1.0,\n",
       " 910: 1.0,\n",
       " 911: 1.0,\n",
       " 912: 0.9090909090909091,\n",
       " 913: 0.0,\n",
       " 914: 1.0,\n",
       " 915: 0.5,\n",
       " 916: 0.0,\n",
       " 917: 1.0,\n",
       " 918: 1.0,\n",
       " 919: 0.9090909090909091,\n",
       " 920: 0.0,\n",
       " 921: 1.0,\n",
       " 923: 1.0,\n",
       " 924: 1.0,\n",
       " 925: 0.0,\n",
       " 926: 1.0,\n",
       " 928: 1.0,\n",
       " 929: 1.0,\n",
       " 930: 0.25,\n",
       " 931: 1.0,\n",
       " 932: 0.8,\n",
       " 933: 1.0,\n",
       " 934: 0.0,\n",
       " 935: 1.0,\n",
       " 936: 0.9230769230769231,\n",
       " 938: 1.0,\n",
       " 939: 1.0,\n",
       " 940: 0.0,\n",
       " 941: 1.0,\n",
       " 942: 0.9583333333333334,\n",
       " 943: 1.0,\n",
       " 944: 1.0,\n",
       " 945: 1.0,\n",
       " 946: 1.0,\n",
       " 947: 1.0,\n",
       " 948: 1.0,\n",
       " 949: 1.0,\n",
       " 950: 0.0,\n",
       " 951: 1.0,\n",
       " 952: 1.0,\n",
       " 953: 1.0,\n",
       " 954: 0.8333333333333334,\n",
       " 955: 0.8,\n",
       " 956: 1.0,\n",
       " 957: 1.0,\n",
       " 958: 1.0,\n",
       " 959: 1.0,\n",
       " 960: 0.0,\n",
       " 961: 1.0,\n",
       " 962: 0.0,\n",
       " 963: 0.6666666666666666,\n",
       " 964: 0.5,\n",
       " 965: 1.0,\n",
       " 967: 1.0,\n",
       " 968: 1.0,\n",
       " 969: 0.9230769230769231,\n",
       " 970: 1.0,\n",
       " 971: 1.0,\n",
       " 972: 1.0,\n",
       " 973: 1.0,\n",
       " 974: 1.0,\n",
       " 975: 1.0,\n",
       " 976: 0.0,\n",
       " 977: 1.0,\n",
       " 978: 1.0,\n",
       " 979: 1.0,\n",
       " 981: 1.0,\n",
       " 982: 1.0,\n",
       " 983: 1.0,\n",
       " 984: 1.0,\n",
       " 985: 1.0,\n",
       " 986: 0.0,\n",
       " 987: 0.5,\n",
       " 988: 1.0,\n",
       " 989: 0.0,\n",
       " 990: 0.9,\n",
       " 991: 0.0,\n",
       " 992: 1.0,\n",
       " 993: 0.6666666666666666,\n",
       " 994: 1.0,\n",
       " 995: 1.0,\n",
       " 996: 0.0,\n",
       " 997: 1.0,\n",
       " 998: 0.5,\n",
       " 999: 1.0,\n",
       " 1000: 1.0,\n",
       " 1001: 0.5,\n",
       " 1002: 1.0,\n",
       " 1004: 1.0,\n",
       " 1005: 0.0,\n",
       " 1006: 0.25,\n",
       " 1007: 1.0,\n",
       " 1008: 1.0,\n",
       " 1009: 0.8,\n",
       " 1010: 1.0,\n",
       " 1011: 1.0,\n",
       " 1012: 1.0,\n",
       " 1013: 1.0,\n",
       " 1014: 0.8,\n",
       " 1015: 0.75,\n",
       " 1016: 1.0,\n",
       " 1017: 1.0,\n",
       " 1018: 0.75,\n",
       " 1020: 1.0,\n",
       " 1021: 1.0,\n",
       " 1023: 1.0,\n",
       " 1024: 1.0,\n",
       " 1026: 1.0,\n",
       " 1027: 0.0,\n",
       " 1028: 1.0,\n",
       " 1029: 0.0,\n",
       " 1030: 0.42857142857142855,\n",
       " 1031: 0.8888888888888888,\n",
       " 1032: 0.0,\n",
       " 1033: 1.0,\n",
       " 1034: 0.5,\n",
       " 1035: 1.0,\n",
       " 1036: 0.0,\n",
       " 1037: 0.0,\n",
       " 1038: 1.0,\n",
       " 1039: 0.0,\n",
       " 1040: 0.875,\n",
       " 1041: 1.0,\n",
       " 1042: 1.0,\n",
       " 1043: 1.0,\n",
       " 1046: 0.8823529411764706,\n",
       " 1047: 0.0,\n",
       " 1048: 1.0,\n",
       " 1050: 1.0,\n",
       " 1051: 0.0,\n",
       " 1052: 0.8888888888888888,\n",
       " 1053: 1.0,\n",
       " 1054: 0.0,\n",
       " 1056: 0.8333333333333334,\n",
       " 1057: 0.5,\n",
       " 1058: 1.0,\n",
       " 1059: 1.0,\n",
       " 1060: 1.0,\n",
       " 1061: 1.0,\n",
       " 1062: 0.0,\n",
       " 1063: 0.9230769230769231,\n",
       " 1064: 1.0,\n",
       " 1065: 0.3333333333333333,\n",
       " 1066: 1.0,\n",
       " 1067: 1.0,\n",
       " 1068: 1.0,\n",
       " 1069: 0.8,\n",
       " 1070: 0.0,\n",
       " 1071: 1.0,\n",
       " 1072: 0.0,\n",
       " 1073: 1.0,\n",
       " 1074: 0.7142857142857143,\n",
       " 1075: 0.0,\n",
       " 1076: 1.0,\n",
       " 1077: 1.0,\n",
       " 1078: 0.0,\n",
       " 1079: 1.0,\n",
       " 1080: 1.0,\n",
       " 1081: 0.6,\n",
       " 1082: 1.0,\n",
       " 1083: 0.0,\n",
       " 1084: 0.5714285714285714,\n",
       " 1085: 0.0,\n",
       " 1086: 0.0,\n",
       " 1087: 1.0,\n",
       " 1088: 1.0,\n",
       " 1089: 1.0,\n",
       " 1090: 1.0,\n",
       " 1092: 0.0,\n",
       " 1093: 0.0,\n",
       " 1094: 0.8888888888888888,\n",
       " 1095: 1.0,\n",
       " 1096: 1.0,\n",
       " 1097: 1.0,\n",
       " 1098: 1.0,\n",
       " 1099: 0.0,\n",
       " 1100: 1.0,\n",
       " 1101: 1.0,\n",
       " 1102: 1.0,\n",
       " 1103: 0.8888888888888888,\n",
       " 1104: 1.0,\n",
       " 1105: 0.6666666666666666,\n",
       " 1106: 1.0,\n",
       " 1107: 1.0,\n",
       " 1108: 0.0,\n",
       " 1109: 1.0,\n",
       " 1110: 0.0,\n",
       " 1111: 1.0,\n",
       " 1112: 1.0,\n",
       " 1113: 0.8,\n",
       " 1114: 0.9090909090909091,\n",
       " 1115: 1.0,\n",
       " 1116: 0.8571428571428571,\n",
       " 1117: 1.0,\n",
       " 1119: 1.0,\n",
       " 1120: 0.5,\n",
       " 1121: 1.0,\n",
       " 1122: 0.8,\n",
       " 1123: 1.0,\n",
       " 1124: 1.0,\n",
       " 1125: 1.0,\n",
       " 1126: 0.0,\n",
       " 1128: 0.0,\n",
       " 1129: 1.0,\n",
       " 1130: 1.0,\n",
       " 1131: 0.5,\n",
       " 1132: 1.0,\n",
       " 1133: 1.0,\n",
       " 1134: 1.0,\n",
       " 1136: 0.0,\n",
       " 1138: 1.0,\n",
       " 1140: 1.0,\n",
       " 1141: 1.0,\n",
       " 1142: 1.0,\n",
       " 1143: 1.0,\n",
       " 1145: 1.0,\n",
       " 1147: 1.0,\n",
       " 1148: 1.0,\n",
       " 1149: 0.0,\n",
       " 1150: 0.0,\n",
       " 1151: 1.0,\n",
       " 1152: 0.0,\n",
       " 1153: 1.0,\n",
       " 1154: 0.8571428571428571,\n",
       " 1155: 0.75,\n",
       " 1156: 0.0,\n",
       " 1158: 1.0,\n",
       " 1159: 0.0,\n",
       " 1160: 1.0,\n",
       " 1161: 1.0,\n",
       " 1162: 0.0,\n",
       " 1163: 1.0,\n",
       " 1164: 0.0,\n",
       " 1166: 1.0,\n",
       " 1167: 1.0,\n",
       " 1168: 1.0,\n",
       " 1169: 1.0,\n",
       " 1170: 1.0,\n",
       " 1171: 0.0,\n",
       " 1172: 1.0,\n",
       " 1173: 1.0,\n",
       " 1174: 0.0,\n",
       " 1175: 1.0,\n",
       " 1176: 1.0,\n",
       " 1178: 0.0,\n",
       " 1179: 0.8888888888888888,\n",
       " 1180: 1.0,\n",
       " 1181: 1.0,\n",
       " 1182: 0.0,\n",
       " 1185: 0.0,\n",
       " 1186: 1.0,\n",
       " 1187: 1.0,\n",
       " 1188: 1.0,\n",
       " 1189: 0.0,\n",
       " 1191: 0.0,\n",
       " 1192: 1.0,\n",
       " 1193: 0.75,\n",
       " 1194: 0.0,\n",
       " 1195: 1.0,\n",
       " 1196: 1.0,\n",
       " 1197: 1.0,\n",
       " 1199: 0.0,\n",
       " 1200: 1.0,\n",
       " 1202: 1.0,\n",
       " 1204: 0.0,\n",
       " 1205: 1.0,\n",
       " 1206: 0.0,\n",
       " 1207: 1.0,\n",
       " 1208: 0.0,\n",
       " 1209: 0.0,\n",
       " 1210: 1.0,\n",
       " 1211: 1.0,\n",
       " 1212: 0.0,\n",
       " 1213: 0.0,\n",
       " 1214: 1.0,\n",
       " 1215: 0.0,\n",
       " 1216: 0.4,\n",
       " 1218: 1.0,\n",
       " 1219: 0.3333333333333333,\n",
       " 1220: 1.0,\n",
       " 1221: 1.0,\n",
       " 1223: 0.6666666666666666,\n",
       " 1224: 0.0,\n",
       " 1225: 0.0,\n",
       " 1226: 1.0,\n",
       " 1227: 1.0,\n",
       " 1228: 0.0,\n",
       " 1229: 1.0,\n",
       " 1230: 1.0,\n",
       " 1231: 0.0,\n",
       " 1232: 1.0,\n",
       " 1233: 0.0,\n",
       " 1234: 0.0,\n",
       " 1235: 1.0,\n",
       " 1236: 0.0,\n",
       " 1237: 1.0,\n",
       " 1238: 1.0,\n",
       " 1239: 1.0,\n",
       " 1240: 0.8888888888888888,\n",
       " 1242: 1.0,\n",
       " 1243: 1.0,\n",
       " 1244: 1.0,\n",
       " 1245: 1.0,\n",
       " 1246: 1.0,\n",
       " 1247: 0.5,\n",
       " 1248: 0.0,\n",
       " 1249: 0.0,\n",
       " 1250: 1.0,\n",
       " 1252: 0.0,\n",
       " 1253: 1.0,\n",
       " 1254: 0.0,\n",
       " 1255: 1.0,\n",
       " 1257: 1.0,\n",
       " 1259: 1.0,\n",
       " 1260: 0.0,\n",
       " 1261: 1.0,\n",
       " 1262: 1.0,\n",
       " 1263: 0.8,\n",
       " 1264: 1.0,\n",
       " 1265: 1.0,\n",
       " 1266: 1.0,\n",
       " 1267: 0.8,\n",
       " 1268: 1.0,\n",
       " 1269: 0.0,\n",
       " 1270: 1.0,\n",
       " 1272: 1.0,\n",
       " 1273: 0.5,\n",
       " 1274: 1.0,\n",
       " 1276: 0.0,\n",
       " 1277: 0.0,\n",
       " 1278: 0.0,\n",
       " 1279: 1.0,\n",
       " 1280: 1.0,\n",
       " 1282: 1.0,\n",
       " 1284: 0.5,\n",
       " 1286: 1.0,\n",
       " 1287: 1.0,\n",
       " 1289: 0.8571428571428571,\n",
       " 1290: 0.0,\n",
       " 1291: 0.0,\n",
       " 1292: 1.0,\n",
       " 1293: 0.0,\n",
       " 1294: 1.0,\n",
       " 1295: 1.0,\n",
       " 1297: 0.5,\n",
       " 1298: 0.0,\n",
       " 1299: 1.0,\n",
       " 1301: 0.0,\n",
       " 1302: 0.0,\n",
       " 1303: 0.0,\n",
       " 1304: 1.0,\n",
       " 1306: 1.0,\n",
       " 1307: 1.0,\n",
       " 1308: 1.0,\n",
       " 1309: 0.0,\n",
       " 1311: 0.0,\n",
       " 1312: 1.0,\n",
       " 1314: 1.0,\n",
       " 1315: 0.0,\n",
       " 1316: 1.0,\n",
       " 1317: 0.0,\n",
       " 1318: 1.0,\n",
       " 1319: 0.0,\n",
       " 1320: 1.0,\n",
       " 1321: 0.0,\n",
       " 1322: 0.0,\n",
       " 1323: 1.0,\n",
       " 1324: 0.0,\n",
       " 1325: 0.0,\n",
       " 1326: 1.0,\n",
       " 1327: 0.75,\n",
       " 1330: 1.0,\n",
       " 1331: 1.0,\n",
       " 1332: 1.0,\n",
       " 1333: 1.0,\n",
       " 1336: 0.0,\n",
       " 1337: 1.0,\n",
       " 1338: 1.0,\n",
       " 1339: 0.0,\n",
       " 1340: 0.8,\n",
       " 1341: 0.0,\n",
       " 1342: 0.0,\n",
       " 1343: 1.0,\n",
       " 1344: 0.0,\n",
       " 1346: 0.0,\n",
       " 1348: 0.0,\n",
       " 1350: 0.0,\n",
       " 1351: 0.0,\n",
       " 1352: 0.0,\n",
       " 1353: 0.0,\n",
       " 1354: 1.0,\n",
       " 1355: 0.0,\n",
       " 1356: 1.0,\n",
       " 1357: 0.0,\n",
       " 1358: 1.0,\n",
       " 1359: 1.0,\n",
       " 1361: 0.0,\n",
       " 1362: 0.0,\n",
       " 1363: 1.0,\n",
       " 1364: 0.0,\n",
       " 1365: 0.0,\n",
       " 1367: 1.0,\n",
       " 1368: 0.6666666666666666,\n",
       " 1369: 1.0,\n",
       " 1370: 1.0,\n",
       " 1371: 0.0,\n",
       " 1372: 0.0,\n",
       " 1374: 1.0,\n",
       " 1376: 1.0,\n",
       " 1378: 0.6666666666666666,\n",
       " 1381: 0.3333333333333333,\n",
       " 1382: 0.0,\n",
       " 1383: 1.0,\n",
       " 1384: 0.0,\n",
       " 1385: 1.0,\n",
       " 1386: 0.0,\n",
       " 1387: 0.0,\n",
       " 1388: 1.0,\n",
       " 1389: 1.0,\n",
       " 1390: 0.0,\n",
       " 1392: 0.0,\n",
       " 1393: 1.0,\n",
       " 1395: 1.0,\n",
       " 1397: 1.0,\n",
       " 1398: 0.0,\n",
       " 1400: 0.6666666666666666,\n",
       " 1401: 1.0,\n",
       " 1402: 1.0,\n",
       " 1404: 1.0,\n",
       " 1406: 1.0,\n",
       " 1407: 0.0,\n",
       " 1408: 0.8,\n",
       " 1409: 1.0,\n",
       " 1410: 1.0,\n",
       " 1412: 1.0,\n",
       " 1413: 1.0,\n",
       " 1414: 0.0,\n",
       " 1415: 1.0,\n",
       " 1416: 0.0,\n",
       " 1417: 0.5,\n",
       " 1418: 0.0,\n",
       " 1419: 0.5,\n",
       " 1420: 1.0,\n",
       " 1421: 1.0,\n",
       " 1422: 1.0,\n",
       " 1423: 0.0,\n",
       " 1424: 0.0,\n",
       " 1425: 0.0,\n",
       " 1426: 0.0,\n",
       " 1427: 1.0,\n",
       " 1428: 0.0,\n",
       " 1429: 1.0,\n",
       " 1431: 1.0,\n",
       " 1432: 0.0,\n",
       " 1433: 1.0,\n",
       " 1435: 0.6666666666666666,\n",
       " 1436: 1.0,\n",
       " 1437: 1.0,\n",
       " 1438: 0.9,\n",
       " 1439: 1.0,\n",
       " 1440: 1.0,\n",
       " 1441: 0.8,\n",
       " 1442: 1.0,\n",
       " 1443: 0.8,\n",
       " 1446: 1.0,\n",
       " 1448: 0.0,\n",
       " 1449: 1.0,\n",
       " 1450: 0.0,\n",
       " 1451: 0.0,\n",
       " 1452: 0.0,\n",
       " 1454: 0.0,\n",
       " 1546: 0.8333333333333334,\n",
       " 1547: 1.0,\n",
       " 1549: 1.0,\n",
       " 1550: 0.0,\n",
       " 1551: 1.0,\n",
       " 1553: 0.0,\n",
       " 1554: 1.0,\n",
       " 1556: 0.0,\n",
       " 1558: 0.0,\n",
       " 1559: 1.0,\n",
       " 1560: 0.0,\n",
       " 1561: 0.0,\n",
       " 1562: 0.0,\n",
       " 1563: 0.6666666666666666,\n",
       " 1564: 0.0,\n",
       " 1565: 1.0,\n",
       " 1567: 0.0,\n",
       " 1569: 1.0,\n",
       " 1570: 0.0,\n",
       " 1571: 1.0,\n",
       " 1572: 1.0,\n",
       " 1574: 1.0,\n",
       " 1576: 0.75,\n",
       " 1577: 1.0,\n",
       " 1578: 0.0,\n",
       " 1579: 0.0,\n",
       " 1580: 1.0,\n",
       " 1581: 0.0,\n",
       " 1582: 0.0,\n",
       " 1583: 1.0,\n",
       " 1585: 0.0,\n",
       " 1586: 1.0,\n",
       " 1587: 0.0,\n",
       " 1588: 1.0,\n",
       " 1590: 1.0,\n",
       " 1591: 1.0,\n",
       " 1592: 0.0,\n",
       " 1593: 1.0,\n",
       " 1596: 0.0,\n",
       " 1597: 1.0,\n",
       " 1598: 0.0,\n",
       " 1599: 1.0,\n",
       " 1600: 1.0,\n",
       " 1601: 1.0,\n",
       " ...}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# исходная модель\n",
    "accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{327: 0.0,\n",
       " 339: 0.0,\n",
       " 340: 0.0,\n",
       " 342: 0.0,\n",
       " 353: 1.0,\n",
       " 354: 0.0,\n",
       " 357: 0.5,\n",
       " 363: 0.5,\n",
       " 364: 1.0,\n",
       " 367: 1.0,\n",
       " 368: 1.0,\n",
       " 373: 1.0,\n",
       " 374: 1.0,\n",
       " 376: 0.0,\n",
       " 378: 1.0,\n",
       " 379: 1.0,\n",
       " 380: 1.0,\n",
       " 382: 1.0,\n",
       " 383: 0.0,\n",
       " 384: 1.0,\n",
       " 386: 1.0,\n",
       " 388: 1.0,\n",
       " 389: 1.0,\n",
       " 391: 1.0,\n",
       " 393: 0.8,\n",
       " 394: 1.0,\n",
       " 397: 1.0,\n",
       " 399: 1.0,\n",
       " 400: 1.0,\n",
       " 401: 1.0,\n",
       " 402: 1.0,\n",
       " 403: 1.0,\n",
       " 404: 1.0,\n",
       " 405: 1.0,\n",
       " 407: 1.0,\n",
       " 408: 0.8,\n",
       " 409: 0.0,\n",
       " 411: 1.0,\n",
       " 412: 0.5,\n",
       " 413: 1.0,\n",
       " 415: 0.0,\n",
       " 416: 0.0,\n",
       " 417: 1.0,\n",
       " 418: 1.0,\n",
       " 419: 1.0,\n",
       " 420: 0.5,\n",
       " 421: 0.8947368421052632,\n",
       " 422: 0.8333333333333334,\n",
       " 424: 1.0,\n",
       " 425: 1.0,\n",
       " 426: 0.6666666666666666,\n",
       " 427: 1.0,\n",
       " 429: 1.0,\n",
       " 430: 0.5,\n",
       " 431: 1.0,\n",
       " 432: 0.9090909090909091,\n",
       " 434: 1.0,\n",
       " 435: 1.0,\n",
       " 436: 1.0,\n",
       " 438: 1.0,\n",
       " 439: 1.0,\n",
       " 440: 0.0,\n",
       " 441: 0.0,\n",
       " 442: 1.0,\n",
       " 445: 1.0,\n",
       " 446: 1.0,\n",
       " 447: 0.9230769230769231,\n",
       " 449: 1.0,\n",
       " 450: 0.8571428571428571,\n",
       " 451: 1.0,\n",
       " 452: 0.8,\n",
       " 453: 0.8333333333333334,\n",
       " 454: 0.6666666666666666,\n",
       " 456: 0.3333333333333333,\n",
       " 457: 1.0,\n",
       " 458: 1.0,\n",
       " 459: 0.7142857142857143,\n",
       " 460: 1.0,\n",
       " 461: 1.0,\n",
       " 462: 0.9411764705882353,\n",
       " 463: 1.0,\n",
       " 464: 1.0,\n",
       " 465: 0.6666666666666666,\n",
       " 466: 1.0,\n",
       " 467: 0.5,\n",
       " 468: 1.0,\n",
       " 469: 1.0,\n",
       " 470: 1.0,\n",
       " 471: 1.0,\n",
       " 472: 0.6666666666666666,\n",
       " 473: 1.0,\n",
       " 474: 0.0,\n",
       " 475: 1.0,\n",
       " 477: 1.0,\n",
       " 478: 1.0,\n",
       " 480: 0.6666666666666666,\n",
       " 481: 0.5,\n",
       " 482: 1.0,\n",
       " 484: 1.0,\n",
       " 485: 1.0,\n",
       " 486: 1.0,\n",
       " 487: 1.0,\n",
       " 489: 1.0,\n",
       " 490: 1.0,\n",
       " 491: 1.0,\n",
       " 492: 0.9166666666666666,\n",
       " 493: 1.0,\n",
       " 495: 0.0,\n",
       " 496: 1.0,\n",
       " 499: 1.0,\n",
       " 500: 1.0,\n",
       " 502: 0.5,\n",
       " 503: 1.0,\n",
       " 504: 1.0,\n",
       " 505: 1.0,\n",
       " 506: 1.0,\n",
       " 507: 0.9,\n",
       " 508: 1.0,\n",
       " 511: 1.0,\n",
       " 512: 0.5,\n",
       " 513: 1.0,\n",
       " 514: 1.0,\n",
       " 515: 1.0,\n",
       " 516: 1.0,\n",
       " 517: 0.5,\n",
       " 518: 1.0,\n",
       " 520: 1.0,\n",
       " 521: 0.875,\n",
       " 522: 1.0,\n",
       " 523: 1.0,\n",
       " 524: 1.0,\n",
       " 525: 0.8571428571428571,\n",
       " 526: 1.0,\n",
       " 528: 0.0,\n",
       " 529: 0.6666666666666666,\n",
       " 530: 1.0,\n",
       " 532: 1.0,\n",
       " 533: 0.75,\n",
       " 536: 1.0,\n",
       " 537: 1.0,\n",
       " 538: 1.0,\n",
       " 539: 1.0,\n",
       " 540: 1.0,\n",
       " 541: 1.0,\n",
       " 543: 0.0,\n",
       " 544: 1.0,\n",
       " 545: 1.0,\n",
       " 547: 0.5,\n",
       " 548: 1.0,\n",
       " 549: 0.0,\n",
       " 550: 1.0,\n",
       " 551: 0.0,\n",
       " 552: 0.9047619047619048,\n",
       " 553: 1.0,\n",
       " 554: 0.9,\n",
       " 555: 1.0,\n",
       " 556: 1.0,\n",
       " 557: 1.0,\n",
       " 558: 1.0,\n",
       " 559: 1.0,\n",
       " 560: 1.0,\n",
       " 561: 0.95,\n",
       " 562: 0.5,\n",
       " 563: 1.0,\n",
       " 564: 1.0,\n",
       " 565: 1.0,\n",
       " 566: 1.0,\n",
       " 567: 1.0,\n",
       " 568: 1.0,\n",
       " 569: 1.0,\n",
       " 570: 0.5,\n",
       " 571: 0.9230769230769231,\n",
       " 572: 0.5,\n",
       " 573: 1.0,\n",
       " 574: 1.0,\n",
       " 575: 1.0,\n",
       " 576: 0.9166666666666666,\n",
       " 577: 1.0,\n",
       " 578: 0.5,\n",
       " 579: 1.0,\n",
       " 580: 0.6666666666666666,\n",
       " 581: 1.0,\n",
       " 583: 0.9230769230769231,\n",
       " 584: 1.0,\n",
       " 586: 1.0,\n",
       " 587: 1.0,\n",
       " 588: 0.6666666666666666,\n",
       " 589: 0.9473684210526315,\n",
       " 590: 0.6666666666666666,\n",
       " 591: 1.0,\n",
       " 593: 1.0,\n",
       " 594: 1.0,\n",
       " 595: 1.0,\n",
       " 596: 0.9354838709677419,\n",
       " 597: 1.0,\n",
       " 598: 0.75,\n",
       " 599: 1.0,\n",
       " 600: 1.0,\n",
       " 601: 1.0,\n",
       " 602: 1.0,\n",
       " 603: 0.75,\n",
       " 605: 1.0,\n",
       " 606: 0.6666666666666666,\n",
       " 607: 1.0,\n",
       " 608: 0.9545454545454546,\n",
       " 609: 1.0,\n",
       " 610: 0.6666666666666666,\n",
       " 611: 1.0,\n",
       " 612: 1.0,\n",
       " 613: 1.0,\n",
       " 614: 1.0,\n",
       " 615: 0.6666666666666666,\n",
       " 616: 1.0,\n",
       " 617: 0.0,\n",
       " 618: 1.0,\n",
       " 619: 1.0,\n",
       " 620: 1.0,\n",
       " 621: 1.0,\n",
       " 622: 1.0,\n",
       " 624: 0.8888888888888888,\n",
       " 625: 0.9393939393939394,\n",
       " 626: 1.0,\n",
       " 627: 1.0,\n",
       " 628: 1.0,\n",
       " 629: 0.6666666666666666,\n",
       " 630: 0.8571428571428571,\n",
       " 631: 1.0,\n",
       " 632: 0.6666666666666666,\n",
       " 633: 1.0,\n",
       " 635: 0.75,\n",
       " 636: 0.0,\n",
       " 637: 1.0,\n",
       " 638: 1.0,\n",
       " 639: 0.75,\n",
       " 640: 1.0,\n",
       " 641: 1.0,\n",
       " 642: 1.0,\n",
       " 644: 1.0,\n",
       " 645: 0.967741935483871,\n",
       " 646: 1.0,\n",
       " 647: 1.0,\n",
       " 648: 1.0,\n",
       " 649: 1.0,\n",
       " 650: 1.0,\n",
       " 651: 1.0,\n",
       " 652: 1.0,\n",
       " 653: 1.0,\n",
       " 654: 0.6666666666666666,\n",
       " 655: 1.0,\n",
       " 656: 0.0,\n",
       " 657: 1.0,\n",
       " 658: 0.9565217391304348,\n",
       " 659: 0.5,\n",
       " 660: 0.8,\n",
       " 661: 0.5,\n",
       " 662: 1.0,\n",
       " 663: 0.9166666666666666,\n",
       " 664: 1.0,\n",
       " 665: 1.0,\n",
       " 666: 0.9354838709677419,\n",
       " 667: 1.0,\n",
       " 668: 1.0,\n",
       " 669: 0.6666666666666666,\n",
       " 670: 0.8333333333333334,\n",
       " 671: 1.0,\n",
       " 672: 1.0,\n",
       " 673: 1.0,\n",
       " 675: 1.0,\n",
       " 676: 1.0,\n",
       " 677: 1.0,\n",
       " 678: 1.0,\n",
       " 679: 0.0,\n",
       " 680: 1.0,\n",
       " 681: 1.0,\n",
       " 682: 1.0,\n",
       " 683: 1.0,\n",
       " 684: 1.0,\n",
       " 685: 0.0,\n",
       " 686: 1.0,\n",
       " 687: 1.0,\n",
       " 688: 1.0,\n",
       " 689: 0.9166666666666666,\n",
       " 691: 1.0,\n",
       " 692: 1.0,\n",
       " 693: 1.0,\n",
       " 694: 1.0,\n",
       " 695: 1.0,\n",
       " 696: 1.0,\n",
       " 697: 1.0,\n",
       " 698: 1.0,\n",
       " 699: 0.75,\n",
       " 700: 0.9166666666666666,\n",
       " 701: 0.6666666666666666,\n",
       " 702: 1.0,\n",
       " 703: 1.0,\n",
       " 704: 0.8333333333333334,\n",
       " 705: 1.0,\n",
       " 706: 0.8571428571428571,\n",
       " 707: 1.0,\n",
       " 708: 1.0,\n",
       " 709: 0.9047619047619048,\n",
       " 710: 1.0,\n",
       " 711: 1.0,\n",
       " 713: 1.0,\n",
       " 714: 1.0,\n",
       " 715: 0.5,\n",
       " 716: 1.0,\n",
       " 717: 1.0,\n",
       " 718: 1.0,\n",
       " 719: 0.8,\n",
       " 720: 1.0,\n",
       " 721: 0.8,\n",
       " 722: 1.0,\n",
       " 723: 1.0,\n",
       " 724: 1.0,\n",
       " 725: 0.8571428571428571,\n",
       " 726: 1.0,\n",
       " 727: 0.8333333333333334,\n",
       " 728: 1.0,\n",
       " 729: 0.8571428571428571,\n",
       " 730: 1.0,\n",
       " 731: 1.0,\n",
       " 732: 0.9411764705882353,\n",
       " 733: 1.0,\n",
       " 734: 1.0,\n",
       " 735: 1.0,\n",
       " 736: 1.0,\n",
       " 737: 0.8461538461538461,\n",
       " 738: 1.0,\n",
       " 739: 0.8333333333333334,\n",
       " 740: 0.8,\n",
       " 741: 1.0,\n",
       " 742: 0.8,\n",
       " 743: 1.0,\n",
       " 744: 1.0,\n",
       " 745: 1.0,\n",
       " 746: 1.0,\n",
       " 747: 1.0,\n",
       " 748: 0.6666666666666666,\n",
       " 749: 1.0,\n",
       " 750: 1.0,\n",
       " 751: 0.5,\n",
       " 752: 1.0,\n",
       " 753: 1.0,\n",
       " 754: 0.8,\n",
       " 755: 1.0,\n",
       " 756: 0.9333333333333333,\n",
       " 757: 1.0,\n",
       " 758: 1.0,\n",
       " 760: 1.0,\n",
       " 761: 0.8,\n",
       " 763: 1.0,\n",
       " 764: 1.0,\n",
       " 765: 1.0,\n",
       " 766: 1.0,\n",
       " 767: 1.0,\n",
       " 768: 1.0,\n",
       " 769: 0.8,\n",
       " 770: 1.0,\n",
       " 771: 1.0,\n",
       " 772: 1.0,\n",
       " 773: 0.9230769230769231,\n",
       " 774: 1.0,\n",
       " 775: 1.0,\n",
       " 776: 1.0,\n",
       " 777: 1.0,\n",
       " 778: 1.0,\n",
       " 779: 1.0,\n",
       " 780: 0.8888888888888888,\n",
       " 781: 1.0,\n",
       " 782: 1.0,\n",
       " 783: 0.0,\n",
       " 784: 1.0,\n",
       " 786: 1.0,\n",
       " 787: 0.9333333333333333,\n",
       " 788: 0.875,\n",
       " 789: 0.967741935483871,\n",
       " 790: 0.8571428571428571,\n",
       " 791: 1.0,\n",
       " 792: 1.0,\n",
       " 793: 1.0,\n",
       " 794: 0.875,\n",
       " 795: 1.0,\n",
       " 796: 1.0,\n",
       " 797: 1.0,\n",
       " 798: 1.0,\n",
       " 799: 0.7142857142857143,\n",
       " 800: 1.0,\n",
       " 801: 1.0,\n",
       " 802: 0.972972972972973,\n",
       " 803: 0.875,\n",
       " 804: 1.0,\n",
       " 805: 1.0,\n",
       " 806: 0.6666666666666666,\n",
       " 807: 1.0,\n",
       " 808: 1.0,\n",
       " 810: 0.9375,\n",
       " 811: 1.0,\n",
       " 812: 1.0,\n",
       " 813: 1.0,\n",
       " 814: 1.0,\n",
       " 815: 0.75,\n",
       " 816: 0.9,\n",
       " 817: 1.0,\n",
       " 818: 0.5,\n",
       " 819: 1.0,\n",
       " 820: 0.75,\n",
       " 821: 1.0,\n",
       " 823: 1.0,\n",
       " 824: 0.5714285714285714,\n",
       " 825: 1.0,\n",
       " 826: 0.6666666666666666,\n",
       " 827: 1.0,\n",
       " 828: 1.0,\n",
       " 829: 1.0,\n",
       " 830: 1.0,\n",
       " 831: 1.0,\n",
       " 832: 1.0,\n",
       " 833: 1.0,\n",
       " 834: 1.0,\n",
       " 835: 1.0,\n",
       " 837: 1.0,\n",
       " 838: 1.0,\n",
       " 839: 0.5,\n",
       " 840: 1.0,\n",
       " 841: 0.0,\n",
       " 842: 1.0,\n",
       " 843: 1.0,\n",
       " 844: 0.9615384615384616,\n",
       " 845: 1.0,\n",
       " 846: 0.5,\n",
       " 847: 1.0,\n",
       " 849: 1.0,\n",
       " 850: 0.6666666666666666,\n",
       " 851: 1.0,\n",
       " 852: 1.0,\n",
       " 853: 1.0,\n",
       " 854: 0.9166666666666666,\n",
       " 855: 1.0,\n",
       " 856: 0.0,\n",
       " 857: 1.0,\n",
       " 858: 1.0,\n",
       " 859: 1.0,\n",
       " 861: 1.0,\n",
       " 862: 0.6666666666666666,\n",
       " 863: 1.0,\n",
       " 864: 0.6666666666666666,\n",
       " 866: 1.0,\n",
       " 867: 1.0,\n",
       " 868: 1.0,\n",
       " 870: 0.75,\n",
       " 871: 1.0,\n",
       " 872: 1.0,\n",
       " 873: 1.0,\n",
       " 874: 1.0,\n",
       " 875: 1.0,\n",
       " 876: 1.0,\n",
       " 877: 1.0,\n",
       " 878: 1.0,\n",
       " 879: 1.0,\n",
       " 880: 1.0,\n",
       " 881: 0.6666666666666666,\n",
       " 882: 0.7692307692307693,\n",
       " 884: 1.0,\n",
       " 885: 1.0,\n",
       " 886: 1.0,\n",
       " 889: 1.0,\n",
       " 890: 1.0,\n",
       " 891: 1.0,\n",
       " 892: 1.0,\n",
       " 893: 1.0,\n",
       " 894: 1.0,\n",
       " 895: 0.8571428571428571,\n",
       " 896: 1.0,\n",
       " 897: 1.0,\n",
       " 898: 1.0,\n",
       " 899: 1.0,\n",
       " 900: 1.0,\n",
       " 901: 1.0,\n",
       " 902: 1.0,\n",
       " 904: 1.0,\n",
       " 905: 1.0,\n",
       " 906: 1.0,\n",
       " 907: 1.0,\n",
       " 909: 1.0,\n",
       " 910: 1.0,\n",
       " 911: 1.0,\n",
       " 912: 1.0,\n",
       " 913: 1.0,\n",
       " 914: 1.0,\n",
       " 915: 1.0,\n",
       " 916: 1.0,\n",
       " 917: 1.0,\n",
       " 918: 1.0,\n",
       " 919: 1.0,\n",
       " 920: 0.5,\n",
       " 921: 1.0,\n",
       " 923: 1.0,\n",
       " 924: 1.0,\n",
       " 925: 0.6666666666666666,\n",
       " 926: 0.8888888888888888,\n",
       " 928: 1.0,\n",
       " 929: 0.8,\n",
       " 930: 0.5,\n",
       " 931: 0.8333333333333334,\n",
       " 932: 1.0,\n",
       " 933: 1.0,\n",
       " 934: 0.0,\n",
       " 935: 1.0,\n",
       " 936: 0.9230769230769231,\n",
       " 938: 1.0,\n",
       " 939: 1.0,\n",
       " 940: 0.6666666666666666,\n",
       " 941: 1.0,\n",
       " 942: 0.9583333333333334,\n",
       " 943: 1.0,\n",
       " 944: 1.0,\n",
       " 945: 1.0,\n",
       " 946: 1.0,\n",
       " 947: 1.0,\n",
       " 948: 1.0,\n",
       " 949: 1.0,\n",
       " 950: 1.0,\n",
       " 951: 1.0,\n",
       " 952: 1.0,\n",
       " 953: 1.0,\n",
       " 954: 1.0,\n",
       " 955: 1.0,\n",
       " 956: 1.0,\n",
       " 957: 1.0,\n",
       " 958: 1.0,\n",
       " 959: 1.0,\n",
       " 960: 0.75,\n",
       " 961: 0.8888888888888888,\n",
       " 962: 1.0,\n",
       " 963: 0.8333333333333334,\n",
       " 964: 0.75,\n",
       " 965: 1.0,\n",
       " 967: 1.0,\n",
       " 968: 1.0,\n",
       " 969: 0.8461538461538461,\n",
       " 970: 1.0,\n",
       " 971: 1.0,\n",
       " 972: 1.0,\n",
       " 973: 1.0,\n",
       " 974: 1.0,\n",
       " 975: 1.0,\n",
       " 976: 1.0,\n",
       " 977: 0.6666666666666666,\n",
       " 978: 1.0,\n",
       " 979: 0.75,\n",
       " 981: 1.0,\n",
       " 982: 0.9230769230769231,\n",
       " 983: 1.0,\n",
       " 984: 1.0,\n",
       " 985: 1.0,\n",
       " 986: 1.0,\n",
       " 987: 0.5,\n",
       " 988: 1.0,\n",
       " 989: 0.0,\n",
       " 990: 1.0,\n",
       " 991: 0.0,\n",
       " 992: 1.0,\n",
       " 993: 0.6666666666666666,\n",
       " 994: 1.0,\n",
       " 995: 0.75,\n",
       " 996: 1.0,\n",
       " 997: 1.0,\n",
       " 998: 0.75,\n",
       " 999: 1.0,\n",
       " 1000: 1.0,\n",
       " 1001: 1.0,\n",
       " 1002: 1.0,\n",
       " 1004: 1.0,\n",
       " 1005: 1.0,\n",
       " 1006: 0.75,\n",
       " 1007: 0.8571428571428571,\n",
       " 1008: 1.0,\n",
       " 1009: 1.0,\n",
       " 1010: 1.0,\n",
       " 1011: 1.0,\n",
       " 1012: 1.0,\n",
       " 1013: 1.0,\n",
       " 1014: 1.0,\n",
       " 1015: 1.0,\n",
       " 1016: 1.0,\n",
       " 1017: 1.0,\n",
       " 1018: 1.0,\n",
       " 1020: 1.0,\n",
       " 1021: 1.0,\n",
       " 1023: 0.5,\n",
       " 1024: 1.0,\n",
       " 1026: 1.0,\n",
       " 1027: 0.5,\n",
       " 1028: 1.0,\n",
       " 1029: 0.0,\n",
       " 1030: 0.8571428571428571,\n",
       " 1031: 1.0,\n",
       " 1032: 0.0,\n",
       " 1033: 1.0,\n",
       " 1034: 1.0,\n",
       " 1035: 0.8571428571428571,\n",
       " 1036: 1.0,\n",
       " 1037: 0.0,\n",
       " 1038: 1.0,\n",
       " 1039: 1.0,\n",
       " 1040: 0.875,\n",
       " 1041: 1.0,\n",
       " 1042: 1.0,\n",
       " 1043: 1.0,\n",
       " 1046: 0.8823529411764706,\n",
       " 1047: 0.5,\n",
       " 1048: 1.0,\n",
       " 1050: 0.8125,\n",
       " 1051: 1.0,\n",
       " 1052: 0.7777777777777778,\n",
       " 1053: 1.0,\n",
       " 1054: 1.0,\n",
       " 1056: 0.9166666666666666,\n",
       " 1057: 1.0,\n",
       " 1058: 1.0,\n",
       " 1059: 1.0,\n",
       " 1060: 1.0,\n",
       " 1061: 1.0,\n",
       " 1062: 0.0,\n",
       " 1063: 1.0,\n",
       " 1064: 1.0,\n",
       " 1065: 1.0,\n",
       " 1066: 0.0,\n",
       " 1067: 1.0,\n",
       " 1068: 1.0,\n",
       " 1069: 1.0,\n",
       " 1070: 1.0,\n",
       " 1071: 1.0,\n",
       " 1072: 1.0,\n",
       " 1073: 1.0,\n",
       " 1074: 0.7142857142857143,\n",
       " 1075: 0.0,\n",
       " 1076: 1.0,\n",
       " 1077: 1.0,\n",
       " 1078: 1.0,\n",
       " 1079: 0.9230769230769231,\n",
       " 1080: 1.0,\n",
       " 1081: 0.8,\n",
       " 1082: 1.0,\n",
       " 1083: 0.0,\n",
       " 1084: 1.0,\n",
       " 1085: 0.6666666666666666,\n",
       " 1086: 1.0,\n",
       " 1087: 1.0,\n",
       " 1088: 1.0,\n",
       " 1089: 1.0,\n",
       " 1090: 0.3333333333333333,\n",
       " 1092: 0.8333333333333334,\n",
       " 1093: 1.0,\n",
       " 1094: 0.7777777777777778,\n",
       " 1095: 1.0,\n",
       " 1096: 1.0,\n",
       " 1097: 0.8,\n",
       " 1098: 0.5,\n",
       " 1099: 0.0,\n",
       " 1100: 0.0,\n",
       " 1101: 0.0,\n",
       " 1102: 1.0,\n",
       " 1103: 0.7777777777777778,\n",
       " 1104: 1.0,\n",
       " 1105: 0.6666666666666666,\n",
       " 1106: 1.0,\n",
       " 1107: 1.0,\n",
       " 1108: 0.0,\n",
       " 1109: 0.5,\n",
       " 1110: 1.0,\n",
       " 1111: 1.0,\n",
       " 1112: 1.0,\n",
       " 1113: 1.0,\n",
       " 1114: 1.0,\n",
       " 1115: 1.0,\n",
       " 1116: 1.0,\n",
       " 1117: 1.0,\n",
       " 1119: 1.0,\n",
       " 1120: 1.0,\n",
       " 1121: 1.0,\n",
       " 1122: 0.8,\n",
       " 1123: 1.0,\n",
       " 1124: 1.0,\n",
       " 1125: 1.0,\n",
       " 1126: 1.0,\n",
       " 1128: 0.6666666666666666,\n",
       " 1129: 1.0,\n",
       " 1130: 0.5,\n",
       " 1131: 1.0,\n",
       " 1132: 0.6666666666666666,\n",
       " 1133: 1.0,\n",
       " 1134: 1.0,\n",
       " 1136: 0.5,\n",
       " 1138: 1.0,\n",
       " 1140: 0.7777777777777778,\n",
       " 1141: 1.0,\n",
       " 1142: 0.75,\n",
       " 1143: 1.0,\n",
       " 1145: 0.5,\n",
       " 1147: 1.0,\n",
       " 1148: 1.0,\n",
       " 1149: 0.5,\n",
       " 1150: 1.0,\n",
       " 1151: 1.0,\n",
       " 1152: 1.0,\n",
       " 1153: 1.0,\n",
       " 1154: 1.0,\n",
       " 1155: 1.0,\n",
       " 1156: 0.5,\n",
       " 1158: 1.0,\n",
       " 1159: 1.0,\n",
       " 1160: 0.75,\n",
       " 1161: 1.0,\n",
       " 1162: 1.0,\n",
       " 1163: 0.8888888888888888,\n",
       " 1164: 0.0,\n",
       " 1166: 0.0,\n",
       " 1167: 1.0,\n",
       " 1168: 1.0,\n",
       " 1169: 1.0,\n",
       " 1170: 1.0,\n",
       " 1171: 0.0,\n",
       " 1172: 1.0,\n",
       " 1173: 1.0,\n",
       " 1174: 0.75,\n",
       " 1175: 1.0,\n",
       " 1176: 1.0,\n",
       " 1178: 0.5,\n",
       " 1179: 1.0,\n",
       " 1180: 0.0,\n",
       " 1181: 1.0,\n",
       " 1182: 0.0,\n",
       " 1185: 1.0,\n",
       " 1186: 0.0,\n",
       " 1187: 1.0,\n",
       " 1188: 1.0,\n",
       " 1189: 0.0,\n",
       " 1191: 1.0,\n",
       " 1192: 1.0,\n",
       " 1193: 1.0,\n",
       " 1194: 0.0,\n",
       " 1195: 1.0,\n",
       " 1196: 1.0,\n",
       " 1197: 1.0,\n",
       " 1199: 1.0,\n",
       " 1200: 1.0,\n",
       " 1202: 1.0,\n",
       " 1204: 1.0,\n",
       " 1205: 1.0,\n",
       " 1206: 0.75,\n",
       " 1207: 0.5,\n",
       " 1208: 0.3333333333333333,\n",
       " 1209: 0.5,\n",
       " 1210: 1.0,\n",
       " 1211: 0.5,\n",
       " 1212: 1.0,\n",
       " 1213: 0.3333333333333333,\n",
       " 1214: 1.0,\n",
       " 1215: 0.0,\n",
       " 1216: 1.0,\n",
       " 1218: 1.0,\n",
       " 1219: 1.0,\n",
       " 1220: 1.0,\n",
       " 1221: 1.0,\n",
       " 1223: 0.3333333333333333,\n",
       " 1224: 1.0,\n",
       " 1225: 0.5,\n",
       " 1226: 1.0,\n",
       " 1227: 0.75,\n",
       " 1228: 0.75,\n",
       " 1229: 1.0,\n",
       " 1230: 1.0,\n",
       " 1231: 0.5,\n",
       " 1232: 1.0,\n",
       " 1233: 1.0,\n",
       " 1234: 0.6666666666666666,\n",
       " 1235: 1.0,\n",
       " 1236: 0.3333333333333333,\n",
       " 1237: 1.0,\n",
       " 1238: 1.0,\n",
       " 1239: 1.0,\n",
       " 1240: 0.8888888888888888,\n",
       " 1242: 1.0,\n",
       " 1243: 0.75,\n",
       " 1244: 1.0,\n",
       " 1245: 1.0,\n",
       " 1246: 0.5,\n",
       " 1247: 0.5,\n",
       " 1248: 0.5,\n",
       " 1249: 1.0,\n",
       " 1250: 0.8571428571428571,\n",
       " 1252: 1.0,\n",
       " 1253: 1.0,\n",
       " 1254: 0.25,\n",
       " 1255: 1.0,\n",
       " 1257: 1.0,\n",
       " 1259: 0.5,\n",
       " 1260: 1.0,\n",
       " 1261: 0.8,\n",
       " 1262: 1.0,\n",
       " 1263: 0.8,\n",
       " 1264: 1.0,\n",
       " 1265: 0.5,\n",
       " 1266: 0.0,\n",
       " 1267: 1.0,\n",
       " 1268: 1.0,\n",
       " 1269: 1.0,\n",
       " 1270: 1.0,\n",
       " 1272: 1.0,\n",
       " 1273: 0.75,\n",
       " 1274: 1.0,\n",
       " 1276: 1.0,\n",
       " 1277: 0.0,\n",
       " 1278: 0.0,\n",
       " 1279: 1.0,\n",
       " 1280: 1.0,\n",
       " 1282: 0.5,\n",
       " 1284: 1.0,\n",
       " 1286: 1.0,\n",
       " 1287: 1.0,\n",
       " 1289: 1.0,\n",
       " 1290: 0.75,\n",
       " 1291: 1.0,\n",
       " 1292: 1.0,\n",
       " 1293: 1.0,\n",
       " 1294: 1.0,\n",
       " 1295: 0.8,\n",
       " 1297: 1.0,\n",
       " 1298: 0.0,\n",
       " 1299: 1.0,\n",
       " 1301: 1.0,\n",
       " 1302: 0.0,\n",
       " 1303: 0.5,\n",
       " 1304: 1.0,\n",
       " 1306: 0.0,\n",
       " 1307: 0.0,\n",
       " 1308: 1.0,\n",
       " 1309: 0.0,\n",
       " 1311: 1.0,\n",
       " 1312: 1.0,\n",
       " 1314: 0.6666666666666666,\n",
       " 1315: 0.5,\n",
       " 1316: 1.0,\n",
       " 1317: 1.0,\n",
       " 1318: 0.5,\n",
       " 1319: 1.0,\n",
       " 1320: 1.0,\n",
       " 1321: 0.5,\n",
       " 1322: 1.0,\n",
       " 1323: 0.8666666666666667,\n",
       " 1324: 1.0,\n",
       " 1325: 0.0,\n",
       " 1326: 0.6666666666666666,\n",
       " 1327: 1.0,\n",
       " 1330: 1.0,\n",
       " 1331: 1.0,\n",
       " 1332: 0.75,\n",
       " 1333: 1.0,\n",
       " 1336: 0.0,\n",
       " 1337: 0.5,\n",
       " 1338: 1.0,\n",
       " 1339: 0.0,\n",
       " 1340: 1.0,\n",
       " 1341: 0.0,\n",
       " 1342: 0.5,\n",
       " 1343: 1.0,\n",
       " 1344: 0.0,\n",
       " 1346: 1.0,\n",
       " 1348: 1.0,\n",
       " 1350: 1.0,\n",
       " 1351: 1.0,\n",
       " 1352: 0.5,\n",
       " 1353: 0.6666666666666666,\n",
       " 1354: 1.0,\n",
       " 1355: 0.5,\n",
       " 1356: 1.0,\n",
       " 1357: 0.0,\n",
       " 1358: 0.6666666666666666,\n",
       " 1359: 1.0,\n",
       " 1361: 0.6666666666666666,\n",
       " 1362: 1.0,\n",
       " 1363: 0.75,\n",
       " 1364: 0.0,\n",
       " 1365: 1.0,\n",
       " 1367: 1.0,\n",
       " 1368: 1.0,\n",
       " 1369: 1.0,\n",
       " 1370: 1.0,\n",
       " 1371: 1.0,\n",
       " 1372: 0.5,\n",
       " 1374: 1.0,\n",
       " 1376: 1.0,\n",
       " 1378: 1.0,\n",
       " 1381: 1.0,\n",
       " 1382: 1.0,\n",
       " 1383: 1.0,\n",
       " 1384: 1.0,\n",
       " 1385: 1.0,\n",
       " 1386: 0.5,\n",
       " 1387: 1.0,\n",
       " 1388: 1.0,\n",
       " 1389: 1.0,\n",
       " 1390: 0.0,\n",
       " 1392: 1.0,\n",
       " 1393: 1.0,\n",
       " 1395: 0.5,\n",
       " 1397: 1.0,\n",
       " 1398: 0.0,\n",
       " 1400: 0.6666666666666666,\n",
       " 1401: 0.6666666666666666,\n",
       " 1402: 1.0,\n",
       " 1404: 1.0,\n",
       " 1406: 1.0,\n",
       " 1407: 0.0,\n",
       " 1408: 1.0,\n",
       " 1409: 1.0,\n",
       " 1410: 1.0,\n",
       " 1412: 1.0,\n",
       " 1413: 1.0,\n",
       " 1414: 1.0,\n",
       " 1415: 1.0,\n",
       " 1416: 0.0,\n",
       " 1417: 0.5,\n",
       " 1418: 1.0,\n",
       " 1419: 0.5,\n",
       " 1420: 1.0,\n",
       " 1421: 1.0,\n",
       " 1422: 1.0,\n",
       " 1423: 1.0,\n",
       " 1424: 1.0,\n",
       " 1425: 0.5,\n",
       " 1426: 1.0,\n",
       " 1427: 1.0,\n",
       " 1428: 0.75,\n",
       " 1429: 1.0,\n",
       " 1431: 1.0,\n",
       " 1432: 0.0,\n",
       " 1433: 1.0,\n",
       " 1435: 1.0,\n",
       " 1436: 0.875,\n",
       " 1437: 0.5,\n",
       " 1438: 0.9,\n",
       " 1439: 1.0,\n",
       " 1440: 1.0,\n",
       " 1441: 0.8,\n",
       " 1442: 1.0,\n",
       " 1443: 1.0,\n",
       " 1446: 0.6666666666666666,\n",
       " 1448: 1.0,\n",
       " 1449: 0.0,\n",
       " 1450: 0.0,\n",
       " 1451: 1.0,\n",
       " 1452: 0.5,\n",
       " 1454: 0.0,\n",
       " 1546: 0.8333333333333334,\n",
       " 1547: 0.5,\n",
       " 1549: 1.0,\n",
       " 1550: 0.0,\n",
       " 1551: 1.0,\n",
       " 1553: 1.0,\n",
       " 1554: 1.0,\n",
       " 1556: 0.0,\n",
       " 1558: 1.0,\n",
       " 1559: 1.0,\n",
       " 1560: 1.0,\n",
       " 1561: 0.75,\n",
       " 1562: 1.0,\n",
       " 1563: 1.0,\n",
       " 1564: 0.0,\n",
       " 1565: 1.0,\n",
       " 1567: 1.0,\n",
       " 1569: 0.8,\n",
       " 1570: 0.0,\n",
       " 1571: 1.0,\n",
       " 1572: 1.0,\n",
       " 1574: 0.8571428571428571,\n",
       " 1576: 1.0,\n",
       " 1577: 0.75,\n",
       " 1578: 1.0,\n",
       " 1579: 0.2,\n",
       " 1580: 0.875,\n",
       " 1581: 0.5,\n",
       " 1582: 1.0,\n",
       " 1583: 1.0,\n",
       " 1585: 0.5,\n",
       " 1586: 1.0,\n",
       " 1587: 1.0,\n",
       " 1588: 1.0,\n",
       " 1590: 0.75,\n",
       " 1591: 1.0,\n",
       " 1592: 0.5,\n",
       " 1593: 0.0,\n",
       " 1596: 1.0,\n",
       " 1597: 1.0,\n",
       " 1598: 1.0,\n",
       " 1599: 1.0,\n",
       " 1600: 1.0,\n",
       " 1601: 1.0,\n",
       " ...}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_for_classes(y_test, target_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика balanced_accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_target_to_binary(array:np.ndarray, target:int) -> np.ndarray:\n",
    "    res = [1 if x==target else 0 for x in array]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(504, 0),\n",
       " (9576, 0),\n",
       " (3619, 0),\n",
       " (13417, 0),\n",
       " (4200, 0),\n",
       " (6951, 0),\n",
       " (665, 0),\n",
       " (9107, 0),\n",
       " (11530, 0),\n",
       " (666, 0)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_y_train = convert_target_to_binary(y_train, 2)\n",
    "list(zip(y_train, bin_y_train))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(564, 0),\n",
       " (5914, 0),\n",
       " (2562, 0),\n",
       " (537, 0),\n",
       " (5964, 0),\n",
       " (984, 0),\n",
       " (5247, 0),\n",
       " (611, 0),\n",
       " (9645, 0),\n",
       " (1162, 0)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_y_test = convert_target_to_binary(y_test, 2)\n",
    "list(zip(y_test, bin_y_test))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_target_i = convert_target_to_binary(y_pred, 2)\n",
    "balanced_accuracy_score(bin_y_test, bin_target_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_target_o = convert_target_to_binary(target_o, 2)\n",
    "balanced_accuracy_score(bin_y_test, bin_target_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика \"Матрица ошибок\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Получаем уникальные значения в истинных значениях y_true\n",
    "unique_labels = np.unique(y_test)\n",
    "\n",
    "# Обновляем параметр labels, учитывая уникальные метки\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "print(conf_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Получаем уникальные значения в истинных значениях y_true\n",
    "unique_labels = np.unique(y_test)\n",
    "\n",
    "# Обновляем параметр labels, учитывая уникальные метки\n",
    "conf_matrix = confusion_matrix(y_test, target_o, labels=unique_labels)\n",
    "print(conf_matrix) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_clf_i = KNeighborsClassifier(n_neighbors=20)\n",
    "bin_clf_i.fit(X_train, bin_y_train)\n",
    "bin_clf_i.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13485,\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_target_i = bin_clf_i.predict_proba(X_test)\n",
    "len(proba_target_i), proba_target_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc_curve(y_true, y_score, pos_label, average):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, \n",
    "                                     pos_label=pos_label)\n",
    "    roc_auc_value = roc_auc_score(y_true, y_score, average=average)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_value)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[171], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdraw_roc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_y_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_target_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[170], line 4\u001b[0m, in \u001b[0;36mdraw_roc_curve\u001b[1;34m(y_true, y_score, pos_label, average)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_roc_curve\u001b[39m(y_true, y_score, pos_label, average):\n\u001b[0;32m      2\u001b[0m     fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, \n\u001b[0;32m      3\u001b[0m                                      pos_label\u001b[38;5;241m=\u001b[39mpos_label)\n\u001b[1;32m----> 4\u001b[0m     roc_auc_value \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m      6\u001b[0m     lw \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:626\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    624\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[0;32m    625\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    635\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    636\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    640\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:381\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 381\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m     )\n\u001b[0;32m    386\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "draw_roc_curve(bin_y_test, bin_target_i, pos_label=1, average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
